train.py
/media/dungdx4/sda1_mnt/PycharmProjects/g-transformer-v2/exp_mbart_doc/iwslt.binarized.en-vi --save-dir /media/dungdx4/sda1_mnt/PycharmProjects/g-transformer-v2/exp_mbart_doc/run-mbart/iwslt.checkpoints.en-vi --tensorboard-logdir /media/dungdx4/sda1_mnt/PycharmProjects/g-transformer-v2/exp_mbart_doc/run-mbart/iwslt.checkpoints.en-vi --seed 222 --num-workers 4
         --task translation_from_pretrained_bart --arch mbart_large --source-lang en --target-lang vi --langs ar,cs,de,en,es,et,fi,fr,gu,hi,it,ja,kk,ko,lt,lv,my,ne,nl,ro,ru,si,tr,vi,zh
         --encoder-normalize-before --decoder-normalize-before --layernorm-embedding
         --optimizer adam --adam-eps 1e-06 --adam-betas "(0.9, 0.98)"
         --lr-scheduler polynomial_decay --lr 3e-05 --warmup-updates 2500 --total-num-update 40000
         --criterion label_smoothed_cross_entropy --label-smoothing 0.2 --dropout 0.3 --attention-dropout 0.1
         --max-tokens 1024 --update-freq 2 --no-epoch-checkpoints
         --save-interval 1 --save-interval-updates 5000 --keep-interval-updates 10
         --restore-file /media/dungdx4/sda1_mnt/BERT/mbart.cc25/model.pt --reset-optimizer --reset-meters --reset-dataloader --reset-lr-scheduler
         --ddp-backend no_c10d

generate.py
/media/dungdx4/sda1_mnt/PycharmProjects/g-transformer_dev/exp_mbart_doc/iwslt.binarized.en-vi --path /media/dungdx4/sda1_mnt/PycharmProjects/g-transformer_dev/exp_mbart_doc/run-mbart/iwslt.checkpoints.en-vi/checkpoint_best.pt           --gen-subset test --batch-size 3 --beam 3 --max-len-a 1.2 --max-len-b 10          --task translation_doc --source-lang en --target-lang vi          --tokenizer moses --bpe "sentencepiece" --sentencepiece-vocab /media/dungdx4/sda1_mnt/BERT/mbart.cc25/sentence.bpe.model --sacrebleu 	 --doc-mode partial          --langs ar,cs,de,en,es,et,fi,fr,gu,hi,it,ja,kk,ko,lt,lv,my,ne,nl,ro,ru,si,tr,vi,zh --gen-output /media/dungdx4/sda1_mnt/PycharmProjects/g-transformer_dev/exp_mbart_doc/run-mbart/iwslt.results.en-vi/test.iwslt.en-vi
